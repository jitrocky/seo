import streamlit as st
import requests
from bs4 import BeautifulSoup
import nltk
from nltk import word_tokenize, FreqDist
from collections import Counter
import re

# ä¸‹è½½NLTKæ•°æ®ï¼ˆé¦–æ¬¡è·‘ï¼‰
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

st.set_page_config(page_title="SEO Auditor", page_icon="ğŸ”")
st.title("ğŸ” 2025 SEOä¼˜åŒ–å·¥å…· | Simple SEO Auditor")
st.write("è¾“å…¥URLæˆ–å†…å®¹ï¼ŒAIå¸®æ‚¨å®¡è®¡å…³é”®è¯ã€metaå’Œæ„å›¾åŒ¹é…ï¼åŸºäºæœ€æ–°è¶‹åŠ¿ï¼ˆAI Overviews + E-E-A-Tï¼‰ã€‚")

tab1, tab2 = st.tabs(["URLå®¡è®¡", "å†…å®¹å®¡è®¡"])

with tab1:
    url = st.text_input("è¾“å…¥ç½‘ç«™URLï¼ˆe.g., your-site.comï¼‰")
    if st.button("ğŸš€ å®¡è®¡URL", type="primary") and url:
        try:
            response = requests.get(url)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            title = soup.find('title').text if soup.find('title') else "æ— æ ‡é¢˜"
            meta_desc = soup.find('meta', attrs={'name': 'description'})
            desc = meta_desc['content'] if meta_desc else "æ— æè¿°"
            
            # ç®€å•å…³é”®è¯æå–ï¼ˆæ ‡é¢˜/æè¿°ï¼‰
            title_words = re.findall(r'\b[A-Z][a-z]+(?: [A-Z][a-z]+)*\b', title)
            desc_words = re.findall(r'\b[A-Z][a-z]+(?: [A-Z][a-z]+)*\b', desc)
            site_keywords = list(set(title_words + desc_words))[:3]  # Top3å…³é”®è¯
            
            # é•¿åº¦æ£€æŸ¥
            title_len = len(title)
            desc_len = len(desc)
            
            st.success("å®¡è®¡å®Œæˆï¼")
            st.markdown("### ğŸ“Š å½“å‰çŠ¶æ€")
            st.write(f"æ ‡é¢˜ï¼š{title} (é•¿åº¦: {title_len}å­—ï¼Œç†æƒ³50-60)")
            st.write(f"æè¿°ï¼š{desc} (é•¿åº¦: {desc_len}å­—ï¼Œç†æƒ³150-160)")
            
            # åŠ¨æ€å»ºè®®ï¼ˆåŸºäºå…³é”®è¯ï¼Œé¿å…åƒåœ¾ç¤ºä¾‹ï¼‰
            suggestions = []
            if title_len < 50:
                kw_example = site_keywords[0] if site_keywords else "æ ¸å¿ƒå…³é”®è¯"
                suggestions.append(f"æ ‡é¢˜å¤ªçŸ­ï¼šåŠ å…³é”®è¯å¦‚'{kw_example} Montreal 2025'æå‡ç‚¹å‡»ã€‚")
            if desc_len < 150:
                kw_example = site_keywords[0] if site_keywords else "æ„å›¾è¯"
                suggestions.append(f"æè¿°å¤ªçŸ­ï¼šåŠ æ„å›¾è¯å¦‚'æœ€ä½³{ kw_example }æ¨è'ã€‚")
            if not any(word in title.lower() for word in ['2025', 'montreal', 'ai']):
                suggestions.append("ç¼ºå°‘æœ¬åœ°/æ—¶æ•ˆå…³é”®è¯ï¼šåŠ '2025 Montreal SEO'åŒ¹é…AI Overviewsã€‚")
            if "payhip.com" in url.lower():
                suggestions.append("Payhipä¸“å±ï¼šåŠ è‡ªå®šä¹‰meta + schema markupï¼Œæå‡äº§å“snippetã€‚")
            
            st.markdown("### ğŸ’¡ ä¼˜åŒ–å»ºè®® (E-E-A-T + æ„å›¾)")
            for sug in suggestions:
                st.write(f"- {sug}")
            
            st.download_button("ğŸ’¾ ä¸‹è½½æŠ¥å‘Š", data=f"æ ‡é¢˜: {title}\næè¿°: {desc}\nå…³é”®è¯: {site_keywords}\nå»ºè®®: {suggestions}", file_name="seo_url_report.txt")
        except Exception as e:
            st.error(f"æŠ“å–å¤±è´¥ï¼š{str(e)}ã€‚æ£€æŸ¥URLæˆ–CloudflareæŒ¡ä½ï¼ˆè¯•åŠ User-Agentï¼‰ã€‚")

with tab2:
    text = st.text_area("è¾“å…¥å†…å®¹ï¼ˆe.g., äº§å“æè¿°ï¼‰", height=150)
    if st.button("ğŸš€ å®¡è®¡å†…å®¹", type="primary") and text:
        # å…³é”®è¯åˆ†æ
        words = word_tokenize(text.lower())
        filtered_words = [w for w in words if len(w) > 3 and w.isalpha()]
        freq = FreqDist(filtered_words)
        top_keywords = freq.most_common(5)
        
        # æ„å›¾å¾—åˆ† (0-10: å¯†åº¦ + é—®é¢˜è¯ + æ¥æº)
        keyword_density = len(set([k[0] for k in top_keywords])) / len(set(filtered_words)) * 5 if filtered_words else 0
        has_question = bool(re.search(r'ä¸ºä»€ä¹ˆ|å¦‚ä½•|ä»€ä¹ˆ|æœ€ä½³|recommend|how|why', text, re.IGNORECASE))
        has_source = bool(re.search(r'æ ¹æ®|æ¥æº|data|according|source', text, re.IGNORECASE))
        intent_score = int(keyword_density + (3 if has_question else 0) + (2 if has_source else 0))
        intent_score = min(10, intent_score)  # å°é¡¶10
        
        st.success("å®¡è®¡å®Œæˆï¼")
        st.markdown("### ğŸ“Š å…³é”®è¯Top5")
        for kw, count in top_keywords:
            st.write(f"- {kw}: {count}æ¬¡ (å¯†åº¦: {count/len(filtered_words)*100:.1f}%)")
        
        st.markdown("### ğŸ“ˆ æ„å›¾åŒ¹é…å¾—åˆ†")
        st.metric("æ€»åˆ† (0-10)", intent_score, delta=None)
        st.write(f"åˆ†è§£ï¼šå…³é”®è¯å¯†åº¦ {keyword_density:.1f}/5 | é—®é¢˜å¯¼å‘ {3 if has_question else 0}/3 | æ¥æºæƒå¨ {2 if has_source else 0}/2")
        
        # åŠ¨æ€å»ºè®®
        suggestions = [
            f"åŠ é—®é¢˜å¥å¦‚'ä¸ºä»€ä¹ˆé€‰{top_keywords[0][0]}ï¼Ÿ'æå‡æ„å›¾åŒ¹é…ã€‚",
            "èå…¥æ¥æºå¦‚'æ ¹æ®Yelp 2025æ•°æ®'ï¼ŒåŠ å¼ºE-E-A-Tã€‚",
            f"ç›®æ ‡å¯†åº¦ï¼šä¸»å…³é”®è¯'{top_keywords[0][0]}' 2-3%ï¼Œé•¿å°¾1%ï¼ˆAI Overviewså‹å¥½ï¼‰ã€‚"
        ]
        st.markdown("### ğŸ’¡ ä¼˜åŒ–å»ºè®®")
        for sug in suggestions:
            st.write(f"- {sug}")
        
        st.download_button("ğŸ’¾ ä¸‹è½½æŠ¥å‘Š", data=f"å…³é”®è¯: {top_keywords}\nå¾—åˆ†: {intent_score}\nå»ºè®®: {suggestions}", file_name="seo_content_report.txt")

st.sidebar.info("åŸºäº2025è¶‹åŠ¿ï¼šAIæ„å›¾ + E-E-A-T | æ‰©å±•ï¼šåŠ Semrush APIã€‚")
